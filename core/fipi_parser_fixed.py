"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –§–ò–ü–ò –∏ –†–µ—à—É–ï–ì–≠
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –∑–∞–¥–∞–Ω–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
"""

import requests
import cloudscraper
from bs4 import BeautifulSoup
import logging
import time
import random
from typing import List, Dict, Optional
from django.utils import timezone
from learning.models import Subject, Task
from django.db import transaction

logger = logging.getLogger(__name__)


class FipiParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ –§–ò–ü–ò (fipi.ru)"""

    def __init__(self):
        self.base_url = "https://fipi.ru"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def get_subjects(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –§–ò–ü–ò"""
        try:
            response = self.session.get(f"{self.base_url}/ege")
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')
            subjects = []

            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç—ã
            subject_links = soup.find_all('a', href=True)

            for link in subject_links:
                href = link.get('href', '')
                if '/ege/' in href and link.text.strip():
                    subject_name = link.text.strip()
                    if subject_name and len(subject_name) > 2:
                        subjects.append({
                            'name': subject_name,
                            'url': f"{self.base_url}{href}",
                            'source': '–§–ò–ü–ò'
                        })

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(subjects)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –Ω–∞ –§–ò–ü–ò")
            return subjects[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –§–ò–ü–ò: {e}")
            return []

    def get_tasks_for_subject(
            self,
            subject_url: str,
            max_tasks: int = 20) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞"""
        try:
            response = self.session.get(subject_url)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')
            tasks = []

            # –ò—â–µ–º –∑–∞–¥–∞–Ω–∏—è (—ç—Ç–æ –ø—Ä–∏–º–µ—Ä–Ω–∞—è –ª–æ–≥–∏–∫–∞, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞)
            task_elements = soup.find_all(
                ['div', 'p'], class_=lambda x: x and 'task' in str(x).lower())  # type: ignore

            for i, element in enumerate(task_elements[:max_tasks]):
                if i >= max_tasks:
                    break

                task_text = element.get_text(strip=True)
                if len(task_text) > 20:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∑–∞–¥–∞–Ω–∏—è
                    tasks.append({
                        'title': f"–ó–∞–¥–∞–Ω–∏–µ {i+1}",
                        'description': task_text[:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                        'difficulty': random.randint(1, 5),
                        'source': '–§–ò–ü–ò',
                        'created_at': timezone.now()
                    })

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞")
            return tasks

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞–¥–∞–Ω–∏–π: {e}")
            return []


class ReshuEGEParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ –†–µ—à—É–ï–ì–≠ (ege.sdamgia.ru)"""

    def __init__(self):
        self.base_url = "https://ege.sdamgia.ru"
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º cloudscraper –¥–ª—è –æ–±—Ö–æ–¥–∞ Cloudflare
        self.session = cloudscraper.create_scraper(
            browser={
                "browser": "chrome",
                "platform": "windows",
                "mobile": False,
            }
        )
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        })

    def _get_with_retry(
            self,
            url: str,
            max_retries: int = 3,
            backoff_seconds: float = 2.0):
        """GET —Å –ø—Ä–æ—Å—Ç—ã–º–∏ —Ä–µ—Ç—Ä–∞—è–º–∏ –∏ –ø–∞—É–∑–∞–º–∏ –ø—Ä–∏ 403/5xx"""
        last_exc: Optional[Exception] = None
        for attempt in range(1, max_retries + 1):
            try:
                resp = self.session.get(url, timeout=20)
                if resp.status_code in (403, 429):
                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞
                    time.sleep(backoff_seconds * attempt)
                    continue
                resp.raise_for_status()
                return resp
            except Exception as exc:  # noqa: BLE001
                last_exc = exc
                time.sleep(backoff_seconds * attempt)
        if last_exc:
            raise last_exc
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏—è")

    def get_subjects(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –†–µ—à—É–ï–ì–≠"""
        try:
            response = self._get_with_retry(self.base_url)

            soup = BeautifulSoup(response.content, 'html.parser')
            subjects = []

            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç—ã
            subject_links = soup.find_all('a', href=True)

            for link in subject_links:
                href = link.get('href', '')
                if '/subject' in href and link.text.strip():
                    subject_name = link.text.strip()
                    if subject_name and len(subject_name) > 2:
                        subjects.append({
                            'name': subject_name,
                            'url': f"{self.base_url}{href}",
                            'source': '–†–µ—à—É–ï–ì–≠'
                        })

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(subjects)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –Ω–∞ –†–µ—à—É–ï–ì–≠")
            return subjects[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –†–µ—à—É–ï–ì–≠: {e}")
            return []

    def get_tasks_for_subject(
            self,
            subject_url: str,
            max_tasks: int = 20) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞"""
        try:
            response = self._get_with_retry(subject_url)

            soup = BeautifulSoup(response.content, 'html.parser')
            tasks = []

            # –ò—â–µ–º –∑–∞–¥–∞–Ω–∏—è
            task_elements = soup.find_all(
                ['div', 'p'], class_=lambda x: x and 'task' in str(x).lower())  # type: ignore

            for i, element in enumerate(task_elements[:max_tasks]):
                if i >= max_tasks:
                    break

                task_text = element.get_text(strip=True)
                if len(task_text) > 20:
                    tasks.append({
                        'title': f"–ó–∞–¥–∞–Ω–∏–µ {i+1}",
                        'description': task_text[:500],
                        'difficulty': random.randint(1, 5),
                        'source': '–†–µ—à—É–ï–ì–≠',
                        'created_at': timezone.now()
                    })

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞")
            return tasks

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∑–∞–¥–∞–Ω–∏–π: {e}")
            return []


class DataIntegrator:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self):
        self.fipi_parser = FipiParser()
        self.reshu_parser = ReshuEGEParser()

    def integrate_subjects_and_tasks(self, max_tasks_per_subject: int = 20) -> Dict:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–º–µ—Ç—ã –∏ –∑–∞–¥–∞–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        results = {
            'subjects_created': 0,
            'tasks_created': 0,
            'errors': []
        }

        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –§–ò–ü–ò
            logger.info("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –§–ò–ü–ò...")
            fipi_subjects = self.fipi_parser.get_subjects()

            for subject_data in fipi_subjects:
                try:
                    with transaction.atomic():
                        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–º–µ—Ç
                        subject, created = Subject.objects.get_or_create(  # type: ignore
                            name=subject_data['name'],
                            defaults={
                                'exam_type': '–ï–ì–≠'
                            }
                        )

                        if created:
                            results['subjects_created'] += 1
                            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–µ–¥–º–µ—Ç: {subject_data['name']}")

                        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞
                        tasks = self.fipi_parser.get_tasks_for_subject(
                            subject_data['url'],
                            max_tasks_per_subject
                        )

                        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞–Ω–∏—è
                        for task_data in tasks:
                            task, created = Task.objects.get_or_create(  # type: ignore
                                title=task_data['title'],
                                subject=subject,
                                defaults={
                                    'description': task_data['description'],
                                    'difficulty': task_data['difficulty'],
                                    'source': task_data['source'],
                                    'created_at': task_data['created_at']
                                }
                            )

                            if created:
                                results['tasks_created'] += 1

                        logger.info(
                            f"üìö –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(tasks)} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è {subject_data['name']}")

                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        time.sleep(random.uniform(1, 3))

                except Exception as e:
                    error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–µ–¥–º–µ—Ç–∞ {subject_data['name']}: {e}"
                    results['errors'].append(error_msg)
                    logger.error(error_msg)

            # –ü–∞—Ä—Å–∏–Ω–≥ –†–µ—à—É–ï–ì–≠ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            logger.info("‚è∏Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –†–µ—à—É–ï–ì–≠ –æ—Ç–∫–ª—é—á—ë–Ω. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –§–ò–ü–ò.")

            logger.info("üéâ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            return results

        except Exception as e:
            error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}"
            results['errors'].append(error_msg)
            logger.error(error_msg)
            return results


def run_full_parsing(max_tasks_per_subject: int = 20) -> bool:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥"""
    try:
        integrator = DataIntegrator()
        results = integrator.integrate_subjects_and_tasks(max_tasks_per_subject)

        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞:")
        logger.info(f"   –ü—Ä–µ–¥–º–µ—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {results['subjects_created']}")
        logger.info(f"   –ó–∞–¥–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–æ: {results['tasks_created']}")

        if results['errors']:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–æ–∫: {len(results['errors'])}")
            for error in results['errors'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                logger.warning(f"   {error}")

        return len(results['errors']) == 0 or results['tasks_created'] > 0

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return False
