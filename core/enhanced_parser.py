"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –§–ò–ü–ò –∏ –†–µ—à—É–ï–ì–≠

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –∑–∞–¥–∞–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã: requests + BeautifulSoup
"""

import logging
import random
import time

import requests
from bs4 import BeautifulSoup
from django.db import transaction
from django.utils import timezone

from learning.models import Subject, Task

logger = logging.getLogger(__name__)


class FipiParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ –§–ò–ü–ò (fipi.ru)"""

    def __init__(self):
        self.base_url = "https://fipi.ru"
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )

    def get_subjects(self) -> list[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –§–ò–ü–ò"""
        try:
            response = self.session.get(f"{self.base_url}/ege")
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            subjects: list[dict] = []

            subject_links = soup.find_all("a", href=True)

            for link in subject_links:
                href = link.get("href", "")
                if "/ege/" in href and href != "/ege":
                    subject_name = link.get_text(strip=True)
                    if subject_name and len(subject_name) > 2:
                        subjects.append(
                            {
                                "name": subject_name,
                                "url": f"{self.base_url}{href}",
                                "source": "–§–ò–ü–ò",
                            }
                        )

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(subjects)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –Ω–∞ –§–ò–ü–ò")
            return subjects

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –§–ò–ü–ò: {e}")
            return []

    def get_tasks_for_subject(self, subject_url: str, subject_name: str) -> list[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞"""
        try:
            response = self.session.get(subject_url)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            tasks: list[dict] = []

            task_elements = soup.find_all("a", href=True)

            for element in task_elements:
                try:
                    title = element.get_text(strip=True)[:200]
                    if len(title) > 10:
                        task = {
                            "title": title,
                            "description": title,
                            "difficulty": random.randint(1, 5),
                            "source": "–§–ò–ü–ò",
                            "subject_name": subject_name,
                        }
                        tasks.append(task)
                except Exception as task_error:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–¥–∞–Ω–∏—è: {task_error}")
                    continue

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞ {subject_name}")
            return tasks

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏–π –¥–ª—è {subject_name}: {e}")
            return []


class ReshuEGEParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ –†–µ—à—É–ï–ì–≠ (ege.sdamgia.ru)"""

    def __init__(self):
        self.base_url = "https://ege.sdamgia.ru"
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )

    def get_subjects(self) -> list[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –†–µ—à—É–ï–ì–≠"""
        try:
            response = self.session.get(self.base_url)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            subjects: list[dict] = []

            subject_links = soup.find_all("a", href=True)

            for link in subject_links:
                href = link.get("href", "")
                if "/test" in href:
                    subject_name = link.get_text(strip=True)
                    if subject_name and len(subject_name) > 2:
                        subjects.append(
                            {
                                "name": subject_name,
                                "url": f"{self.base_url}{href}",
                                "source": "–†–µ—à—É–ï–ì–≠",
                            }
                        )

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(subjects)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –Ω–∞ –†–µ—à—É–ï–ì–≠")
            return subjects

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å –†–µ—à—É–ï–ì–≠: {e}")
            return []

    def get_tasks_for_subject(self, subject_url: str, subject_name: str) -> list[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞"""
        try:
            response = self.session.get(subject_url)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            tasks: list[dict] = []

            task_elements = soup.find_all("a", href=True)

            for element in task_elements:
                try:
                    title = element.get_text(strip=True)[:200]
                    if len(title) > 10:
                        task = {
                            "title": title,
                            "description": title,
                            "difficulty": random.randint(1, 5),
                            "source": "–†–µ—à—É–ï–ì–≠",
                            "subject_name": subject_name,
                        }
                        tasks.append(task)
                except Exception as task_error:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–¥–∞–Ω–∏—è: {task_error}")
                    continue

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞ {subject_name}")
            return tasks

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏–π –¥–ª—è {subject_name}: {e}")
            return []


class DataIntegrator:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É Django"""

    def __init__(self):
        self.fipi_parser = FipiParser()
        self.reshu_parser = ReshuEGEParser()

    def create_or_update_subject(self, subject_data: dict) -> Subject:
        """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–µ–¥–º–µ—Ç –≤ –±–∞–∑–µ"""
        try:
            exam_type = (
                "–ï–ì–≠"
                if any(
                    word in subject_data["name"].lower()
                    for word in ["–µ–≥—ç", "–ø—Ä–æ—Ñ–∏–ª—å", "–±–∞–∑–∞"]
                )
                else "–û–ì–≠"
            )

            subject, created = Subject.objects.get_or_create(  # type: ignore
                name=subject_data["name"], defaults={"exam_type": exam_type}
            )

            if created:
                logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –ø—Ä–µ–¥–º–µ—Ç: {subject_data['name']}")
            else:
                logger.info(f"–ü—Ä–µ–¥–º–µ—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {subject_data['name']}")

            return subject

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–∞ {subject_data['name']}: {e}")
            raise

    def create_or_update_task(self, task_data: dict, subject: Subject) -> Task:
        """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–¥–∞–Ω–∏–µ –≤ –±–∞–∑–µ"""
        try:
            existing_task = Task.objects.filter(  # type: ignore
                title=task_data["title"][:200], subject=subject
            ).first()

            if existing_task:
                logger.debug(f"–ó–∞–¥–∞–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {task_data['title'][:50]}...")
                return existing_task

            task = Task.objects.create(  # type: ignore
                subject=subject,
                title=task_data["title"][:200],
                description=task_data["description"][:1000],
                difficulty=task_data["difficulty"],
                source=task_data["source"],
                created_at=timezone.now(),
            )

            logger.info(f"–°–æ–∑–¥–∞–Ω–æ –Ω–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ: {task_data['title'][:50]}...")
            return task

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è: {e}")
            raise

    def run_data_update(self, max_tasks_per_subject: int = 50) -> dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        start_time = time.time()
        total_subjects = 0
        total_tasks = 0
        errors: list[str] = []

        try:
            logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")

            logger.info("üìö –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –§–ò–ü–ò...")
            fipi_subjects = self.fipi_parser.get_subjects()

            logger.info("üìö –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –†–µ—à—É–ï–ì–≠...")
            reshu_subjects = self.reshu_parser.get_subjects()

            all_subjects = fipi_subjects + reshu_subjects

            unique_subjects: dict[str, dict] = {}
            for subject in all_subjects:
                name = subject["name"].strip()
                if name not in unique_subjects:
                    unique_subjects[name] = subject

            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(unique_subjects)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤")

            for subject_data in unique_subjects.values():
                try:
                    subject = self.create_or_update_subject(subject_data)
                    total_subjects += 1

                    if subject_data["source"] == "–§–ò–ü–ò":
                        tasks = self.fipi_parser.get_tasks_for_subject(
                            subject_data["url"], subject_data["name"]
                        )
                    else:
                        tasks = self.reshu_parser.get_tasks_for_subject(
                            subject_data["url"], subject_data["name"]
                        )

                    tasks = tasks[:max_tasks_per_subject]

                    with transaction.atomic():
                        for task_data in tasks:
                            try:
                                self.create_or_update_task(task_data, subject)
                                total_tasks += 1
                            except Exception as task_error:
                                errors.append(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è: {task_error}")
                                continue

                    time.sleep(random.uniform(1, 3))

                except Exception as subject_error:
                    error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥–º–µ—Ç–∞ {subject_data['name']}: {subject_error}"
                    errors.append(error_msg)
                    logger.error(error_msg)
                    continue

            execution_time = time.time() - start_time
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–µ–¥–º–µ—Ç–æ–≤: {total_subjects}")
            logger.info(f"üìù –°–æ–∑–¥–∞–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–¥–∞–Ω–∏–π: {total_tasks}")

            if errors:
                logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(errors)} –æ—à–∏–±–æ–∫")
                for error in errors[:5]:
                    logger.warning(f"  - {error}")

            return {
                "success": True,
                "subjects_processed": total_subjects,
                "tasks_processed": total_tasks,
                "execution_time": execution_time,
                "errors": errors,
            }

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            return {
                "success": False,
                "error": str(e),
                "subjects_processed": total_subjects,
                "tasks_processed": total_tasks,
                "execution_time": time.time() - start_time,
            }


def run_data_update() -> dict:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    integrator = DataIntegrator()
    return integrator.run_data_update()


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    result = run_data_update()

    if result["success"]:
        print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –ü—Ä–µ–¥–º–µ—Ç–æ–≤: {result['subjects_processed']}")
        print(f"üìù –ó–∞–¥–∞–Ω–∏–π: {result['tasks_processed']}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result['execution_time']:.2f} —Å–µ–∫")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {result['error']}")
