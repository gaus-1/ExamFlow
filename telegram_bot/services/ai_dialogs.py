from __future__ import annotations

from core.container import Container

try:
    from telegram_bot.bot_handlers import (
        db_create_enhanced_prompt as _legacy_create_enhanced_prompt,  # type: ignore
        db_add_user_message_to_session as _legacy_add_user_message,  # type: ignore
        db_add_assistant_message_to_session as _legacy_add_assistant_message,  # type: ignore
        db_get_or_create_chat_session as _legacy_get_or_create_chat_session,  # type: ignore
    )
except Exception:
    def _legacy_create_enhanced_prompt(user_message: str, session) -> str:  # type: ignore
        return user_message

    def _legacy_add_user_message(session, message):  # type: ignore
        return None

    def _legacy_add_assistant_message(session, message):  # type: ignore
        return None

    def _legacy_get_or_create_chat_session(telegram_user, django_user=None):  # type: ignore
        return None


# –§–∞—Å–∞–¥–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—Ç–æ–Ω–∫–∏–µ –æ–±—ë—Ä—Ç–∫–∏)

def get_or_create_chat_session(telegram_user, django_user=None):  # type: ignore
    return _legacy_get_or_create_chat_session(telegram_user, django_user)


def create_enhanced_prompt(user_message: str, session) -> str:
    return _legacy_create_enhanced_prompt(user_message, session)


def add_user_message_to_session(session, message) -> None:
    _legacy_add_user_message(session, message)


def add_assistant_message_to_session(session, message) -> None:
    _legacy_add_assistant_message(session, message)


def get_ai_response(prompt: str, task_type: str = 'chat', user=None, task=None) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç AI —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π AI API –¥–ª—è –±–æ—Ç–∞ (–ø—Ä—è–º–æ–π Gemini)
        import google.generativeai as genai
        from django.conf import settings
        
        api_key = getattr(settings, 'GEMINI_API_KEY', '')
        if not api_key:
            return '–°–µ—Ä–≤–∏—Å –ò–ò –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Gemini
        genai.configure(api_key=api_key)  # type: ignore
        model = genai.GenerativeModel('gemini-1.5-flash')  # type: ignore
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å —Ä–æ–ª—å—é ExamFlow
        system_prompt = """–¢—ã - ExamFlow AI, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –ï–ì–≠ –∏ –û–ì–≠.

–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—à—å—Å—è –Ω–∞:
üìê –ú–∞—Ç–µ–º–∞—Ç–∏–∫–µ (–ø—Ä–æ—Ñ–∏–ª—å–Ω–∞—è –∏ –±–∞–∑–æ–≤–∞—è, –û–ì–≠) - —É—Ä–∞–≤–Ω–µ–Ω–∏—è, —Ñ—É–Ω–∫—Ü–∏–∏, –≥–µ–æ–º–µ—Ç—Ä–∏—è, –∞–ª–≥–µ–±—Ä–∞
üìù –†—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (–ï–ì–≠ –∏ –û–ì–≠) - –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞, –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è, —Å–æ—á–∏–Ω–µ–Ω–∏—è, –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π
- –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–π —É–º–µ—Å—Ç–Ω—ã–µ —à—É—Ç–∫–∏ –ø–æ —Ç–µ–º–µ
- –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–π—Å—è –∫–∞–∫ "ExamFlow AI" 
- –ü–æ–º–æ–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –ø–æ—à–∞–≥–æ–≤—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏
- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–≤–æ–∏–º –ø—Ä–µ–¥–º–µ—Ç–∞–º - –≤–µ–∂–ª–∏–≤–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤—å –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏–∫—É –∏–ª–∏ —Ä—É—Å—Å–∫–∏–π

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –º–∞–∫—Å–∏–º—É–º 400 —Å–ª–æ–≤."""

        full_prompt = f"{system_prompt}\n\n–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {prompt}"
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        response = model.generate_content(full_prompt)
        
        if response.text:
            answer = response.text.strip()
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è Telegram
            if len(answer) > 4000:
                answer = answer[:4000] + "..."
            return answer
        else:
            return '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.'
            
    except Exception as e:
        return f'–û—à–∏–±–∫–∞ AI —Å–µ—Ä–≤–∏—Å–∞: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ'
